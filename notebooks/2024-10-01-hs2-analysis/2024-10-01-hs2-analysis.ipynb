{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpsteer2 Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "\n",
    "FONT_SIZES = {\"small\": 14, \"medium\": 18, \"large\": 24}\n",
    "\n",
    "PLOT_PARAMS = {\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\"],\n",
    "    \"font.size\": FONT_SIZES.get(\"medium\"),\n",
    "    \"axes.titlesize\": FONT_SIZES.get(\"large\"),\n",
    "    \"axes.labelsize\": FONT_SIZES.get(\"large\"),\n",
    "    \"xtick.labelsize\": FONT_SIZES.get(\"large\"),\n",
    "    \"ytick.labelsize\": FONT_SIZES.get(\"large\"),\n",
    "    \"legend.fontsize\": FONT_SIZES.get(\"medium\"),\n",
    "    \"figure.titlesize\": FONT_SIZES.get(\"medium\"),\n",
    "    \"text.usetex\": True,\n",
    "}\n",
    "\n",
    "COLORS = {\n",
    "    \"pink\": \"#f0529c\",\n",
    "    \"dark_teal\": \"#0a3235\",\n",
    "    \"teal\": \"#105257\",\n",
    "    \"purple\": \"#b11be8\",\n",
    "    \"green\": \"#0fcb8c\",\n",
    "}\n",
    "\n",
    "\n",
    "plt.rcParams.update(PLOT_PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the optimal subset for Helpsteer2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_swaps = pd.read_json(\"hs2_optimal.jsonl\", lines=True)\n",
    "df_feats = pd.read_json(\"features.jsonl\", lines=True)\n",
    "df = df_swaps.merge(df_feats, on=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And get the instances routed to GPT-4 and those routed to Humans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2_gpt4 = df[~df[\"is_swapped\"]].reset_index(drop=True)\n",
    "hs2_gpt4[\"rating_chosen\"] = hs2_gpt4[\"rating_gpt4\"].apply(lambda x: x[0])\n",
    "hs2_gpt4[\"rating_rejected\"] = hs2_gpt4[\"rating_gpt4\"].apply(lambda x: x[1])\n",
    "\n",
    "hs2_hums = df[df[\"is_swapped\"]].reset_index(drop=True)\n",
    "hs2_hums[\"rating_chosen\"] = hs2_hums[\"rating_human\"].apply(lambda x: x[0])\n",
    "hs2_hums[\"rating_rejected\"] = hs2_hums[\"rating_human\"].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important questions:\n",
    "\n",
    "- Using our top ten features, do we find large difference in counts or distribution?\n",
    "- Can we find particular examples with high gain and low gain?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_expertise(df, n=10, normalize: bool = True):\n",
    "    counts = (\n",
    "        pd.DataFrame(\n",
    "            [Counter([s for l in df.subject_of_expertise.to_list() for s in l])]\n",
    "        )\n",
    "        .T.sort_values(by=0, ascending=False)\n",
    "        .rename(columns={0: \"count\"})\n",
    "    )\n",
    "\n",
    "    total = counts[\"count\"].sum()\n",
    "    print(f\"Total num of instances: {total}\")\n",
    "    if normalize:\n",
    "        counts[\"normalize\"] = (counts[\"count\"] / total) * 100\n",
    "\n",
    "    return counts.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(17, 5))\n",
    "get_top_n_expertise(hs2_gpt4).iloc[::-1].rename(\n",
    "    {\"Journalism, media studies and communication\": \"Journalism\"}\n",
    ").normalize.plot.barh(ax=axs[0], color=COLORS.get(\"teal\"))\n",
    "axs[0].set_title(\"Routed to GPT-4\")\n",
    "get_top_n_expertise(hs2_hums).iloc[::-1].normalize.plot.barh(\n",
    "    ax=axs[1], color=COLORS.get(\"teal\")\n",
    ")\n",
    "axs[1].set_title(\"Routed to Humans\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.set_xlabel(\"\\% of instances\")\n",
    "    ax.xaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"hs2_soe.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multipref_soe_rankings(df):\n",
    "    multipref_human_soe = [\n",
    "        \"Chemical engineering\",\n",
    "        \"Religion\",\n",
    "        \"Anthropology\",\n",
    "        \"Chemistry\",\n",
    "        \"Visual arts\",\n",
    "        \"Earth sciences\",\n",
    "        \"Space sciences\",\n",
    "    ]\n",
    "    multipref_gpt4_soe = [\n",
    "        \"Logic\",\n",
    "        \"Transportation\",\n",
    "        \"Architecture and design\",\n",
    "        \"Materials science and engineering\",\n",
    "        \"Library and museum studies\",\n",
    "        \"Media studies and communication\",\n",
    "        \"Military sciences\",\n",
    "        \"Family and consumer science\",\n",
    "    ]\n",
    "\n",
    "    df_soe = (\n",
    "        pd.DataFrame(\n",
    "            [Counter([s for l in df.subject_of_expertise.to_list() for s in l])]\n",
    "        )\n",
    "        .T.sort_values(by=0, ascending=False)\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"count\", \"index\": \"subject\"})\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        df_soe[df_soe[\"subject\"].isin(multipref_human_soe)].reset_index(drop=True),\n",
    "        df_soe[df_soe[\"subject\"].isin(multipref_gpt4_soe)].reset_index(drop=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a grouped bar chart for this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2_gpt4_elevel = hs2_gpt4.expertise_level.value_counts(normalize=True)[\n",
    "    [\"expert domain knowledge\", \"general public\", \"basic domain knowledge\"]\n",
    "].reset_index()\n",
    "hs2_gpt4_elevel[\"routed_to\"] = \"gpt4\"\n",
    "hs2_hums_elevel = hs2_hums.expertise_level.value_counts(normalize=True).reset_index()\n",
    "hs2_hums_elevel[\"routed_to\"] = \"human\"\n",
    "hs2_elevel = pd.concat([hs2_gpt4_elevel, hs2_hums_elevel]).reset_index(drop=True)\n",
    "hs2_elevel[\"percentage\"] = hs2_elevel[\"proportion\"] * 100\n",
    "hs2_elevel = hs2_elevel.replace({\"gpt4\": \"GPT-4\", \"human\": \"Human\"})\n",
    "\n",
    "order = [\"general public\", \"basic domain knowledge\", \"expert domain knowledge\"]\n",
    "pivot_df = hs2_elevel.pivot(\n",
    "    index=\"expertise_level\",\n",
    "    columns=\"routed_to\",\n",
    "    values=\"percentage\",\n",
    ")\n",
    "pivot_df = pivot_df.reindex(order)\n",
    "pivot_df.index = [o.title() for o in order]\n",
    "\n",
    "# Plotting the grouped bar chart\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7.5, 4))\n",
    "pivot_df.plot(kind=\"bar\", ax=ax, color=[COLORS.get(\"teal\"), COLORS.get(\"pink\")])\n",
    "\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_ylabel(\"\")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax.legend(\n",
    "    # loc=\"lower right\",\n",
    "    frameon=False,\n",
    "    title=\"Routed to...\",\n",
    ")\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    [\"General\\npublic\", \"Basic domain\\nknowledge\", \"Expert domain\\nknowledge\"],\n",
    "    rotation=0,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"hs2_loe.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2_gpt4.open_endedness.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "human_annotations = hs2_hums[\"pref_human\"].to_list()\n",
    "gpt4_annotations = hs2_hums[\"pref_gpt4\"].to_list()\n",
    "\n",
    "\n",
    "pct_agreement = len(hs2_hums[hs2_hums[\"pref_human\"] == hs2_hums[\"pref_gpt4\"]]) / len(\n",
    "    hs2_hums\n",
    ")\n",
    "score = cohen_kappa_score(human_annotations, gpt4_annotations)\n",
    "\n",
    "print(pct_agreement, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2_gpt4.entity_sim.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2_hums.entity_sim.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2_gpt4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2_hums.complexity_of_intents.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "dim = \"cosine_sim\"\n",
    "bins = 30\n",
    "maxv = 400\n",
    "hs2_hums[dim].hist(\n",
    "    ax=ax,\n",
    "    bins=bins,\n",
    "    alpha=0.5,\n",
    "    density=False,\n",
    "    grid=False,\n",
    "    label=\"Human\",\n",
    "    edgecolor=COLORS.get(\"pink\"),\n",
    "    color=COLORS.get(\"pink\"),\n",
    ")\n",
    "hs2_gpt4[dim].hist(\n",
    "    ax=ax,\n",
    "    bins=bins,\n",
    "    alpha=0.5,\n",
    "    density=False,\n",
    "    grid=False,\n",
    "    label=\"GPT-4\",\n",
    "    edgecolor=COLORS.get(\"teal\"),\n",
    "    color=COLORS.get(\"teal\"),\n",
    ")\n",
    "ax.vlines(0.33, 0, maxv, color=\"k\", linestyles=\"--\")\n",
    "ax.vlines(0.67, 0, maxv, color=\"k\", linestyles=\"--\")\n",
    "# ax.text(0.33 - 0.05, 0 - 50, \"0.33\")\n",
    "# ax.text(0.67 - 0.05, 0 - 50, \"0.67\")\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xticks([0, 0.33, 0.67, 1.0])\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.set_title(\"ROUGE-L\" if dim == \"rouge\" else \"Cosine similarity\")\n",
    "ax.legend(title=\"Routed to:\", frameon=False, ncols=2, bbox_to_anchor=(1.05, -0.10))\n",
    "ax.set_ylabel(\"Counts\")\n",
    "plt.tight_layout()\n",
    "# hs2_hums[dim].plot.kde(alpha=0.5)\n",
    "# hs2_gpt4[dim].plot.kde(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2_hums[\"bertscore_length\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = \"prompt_len\"\n",
    "hs2_hums[dim].hist(alpha=0.5, bins=30)\n",
    "hs2_gpt4[dim].hist(alpha=0.5, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = \"expertise_level\"\n",
    "print(\"human\")\n",
    "print(hs2_hums[dim].value_counts(normalize=True).to_markdown())\n",
    "print(\"gpt4\")\n",
    "print(hs2_gpt4[dim].value_counts(normalize=True).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = hs2_gpt4[\n",
    "    [\n",
    "        \"Computer sciences\" in row[\"subject_of_expertise\"]\n",
    "        for _, row in hs2_gpt4.iterrows()\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2_gpt4.expertise_level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(\n",
    "    [\n",
    "        j\n",
    "        for i in hs2_gpt4[\n",
    "            hs2_gpt4.expertise_level == \"basic domain knowledge\"\n",
    "        ].subject_of_expertise.to_list()\n",
    "        for j in i\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1504 / 2706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs[cs.expertise_level == \"basic domain knowledge\"][\"prompt\"].sample(10).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs[cs.expertise_level == \"general public\"][\"prompt\"].sample(10).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2_gpt4[hs2_gpt4[\"pref_human\"] != hs2_gpt4[\"pref_gpt4\"]].reset_index(drop=True).to_csv(\n",
    "    \"hs2_routed_to_gpt4_disagree.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humpref = hs2_gpt4[\"pref_human\"]\n",
    "gptpref = hs2_gpt4[\"pref_gpt4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(humpref == gptpref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2038 / len(humpref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(humpref.to_list(), gptpref.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
