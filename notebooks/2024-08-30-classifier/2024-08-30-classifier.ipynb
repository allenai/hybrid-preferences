{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "from ast import literal_eval\n",
    "\n",
    "from src.utils import find_meta_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we'll combine the lexical-only features and those with Bowen's features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical = pd.read_csv(\"lexical_only.csv\").dropna()\n",
    "lexical_bowen = pd.read_csv(\"with_bowen.csv\").dropna()\n",
    "\n",
    "\n",
    "lexical_features = []\n",
    "\n",
    "# Add hashes for lexical features\n",
    "lexical = lexical.rename(\n",
    "    columns={\n",
    "        \"Unnamed: 0\": \"experiment_name\",\n",
    "        \"rouge>0.4\": \"rouge\",\n",
    "        \"bertscore>0.8\": \"bertscore\",\n",
    "        \"cosine_sim>0.8\": \"cosine_sim\",\n",
    "        \"entity_sim>0.8\": \"entity_sim\",\n",
    "        \"bertscore_length>0.4\": \"bertscore_length\",\n",
    "    }\n",
    ")\n",
    "lexical[\"hash\"] = lexical[\"experiment_name\"].apply(\n",
    "    lambda x: hashlib.md5(\n",
    "        x.split(\"FEATS\")[-1].removeprefix(\"_\").encode(\"utf-8\")\n",
    "    ).hexdigest(),\n",
    ")\n",
    "lexical_feats = lexical[\n",
    "    [\n",
    "        \"hash\",\n",
    "        \"rouge\",\n",
    "        \"bertscore\",\n",
    "        \"cosine_sim\",\n",
    "        \"entity_sim\",\n",
    "        \"bertscore_length\",\n",
    "        \"label\",\n",
    "        \"Overall\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "lexical_bowen = lexical_bowen[\n",
    "    [\"hash\"]\n",
    "    + [\"rouge\", \"bertscore\", \"cosine_sim\", \"entity_sim\", \"bertscore_length\"]\n",
    "    + [col for col in lexical_bowen.columns if \"=\" in col]\n",
    "    + [\"label\", \"Overall\"]\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.concat([lexical_feats, lexical_bowen]).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get proportion of instances that fulfill the conditions\n",
    "\n",
    "1. For each row, get features that were activated\n",
    "2. Then for each activated feature, we get the proportion by looking at the feature dataframe.\n",
    "3. The proportion is computed as: `number_of_instance_that_fulfill_a_single_condition` / `total_number_of_instances`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\"helpsteer2_featureset.csv\").dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect nan columns\n",
    "rows_with_nan = features_df[features_df.isna().any(axis=1)]\n",
    "nan_columns = rows_with_nan.columns[rows_with_nan.isna().any()]\n",
    "df_nan_columns = rows_with_nan[nan_columns]\n",
    "df_nan_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what you're going to do instead, is to take the binary_cols, and then for each element of that binary_cols, you compute the \"weight\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_instances(feat: str, features_df: \"pd.DataFrame\") -> float:\n",
    "    total = len(features_df)\n",
    "    # Hacky approach\n",
    "    thresholds = {\n",
    "        \"rouge\": 0.4,\n",
    "        \"bertscore\": 0.8,\n",
    "        \"cosine_sim\": 0.8,\n",
    "        \"entity_sim\": 0.8,\n",
    "        \"bertscore_length\": 0.4,\n",
    "    }\n",
    "    if feat in thresholds:\n",
    "        thresh = thresholds[feat]\n",
    "        return sum(features_df[feat] > thresh) / total\n",
    "    else:\n",
    "        # Parse the feature\n",
    "        feat_name, value = feat.split(\"=\")\n",
    "        meta_category = find_meta_category(feat_name)\n",
    "        if meta_category == \"scalar\":\n",
    "            v = value.replace(\"_\", \" \")\n",
    "            return features_df[feat_name].value_counts().get(v) / total\n",
    "        elif meta_category == \"closed_set\":\n",
    "            v = value.replace(\"_\", \" \")\n",
    "            list_of_values = features_df[feat_name].apply(literal_eval).tolist()\n",
    "            return sum([1 if v in listval else 0 for listval in list_of_values]) / total\n",
    "        elif meta_category == \"open_set\":\n",
    "            list_of_values = features_df[feat_name].apply(literal_eval).tolist()\n",
    "            return sum([1 if listval else 0 for listval in list_of_values]) / total\n",
    "\n",
    "        return find_meta_category(feat_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = df.columns[df.isin([0, 1]).all()]  # get binary columns\n",
    "feat_map = {\n",
    "    feat: compute_instances(feat, features_df) for feat in feats if feat != \"label\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use those ratios and create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df = df.apply(\n",
    "    lambda row: row.map(lambda x: feat_map.get(row.name, 1) if x == 1 else x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hash', 'rouge', 'bertscore', 'cosine_sim', 'entity_sim',\n",
       "       'bertscore_length', 'label', 'Overall', 'complexity_of_intents=complex',\n",
       "       'complexity_of_intents=moderate', 'complexity_of_intents=simple',\n",
       "       'expertise_level=basic_domain_knowledge',\n",
       "       'expertise_level=expert_domain_knowledge',\n",
       "       'expertise_level=general_public', 'format_constraints=1',\n",
       "       'languages=English', 'open_endedness=high', 'open_endedness=low',\n",
       "       'open_endedness=moderate', 'open_endedness=no', 'safety_concern=high',\n",
       "       'safety_concern=low', 'safety_concern=moderate', 'safety_concern=safe',\n",
       "       'subject_of_expertise=Agriculture', 'subject_of_expertise=Anthropology',\n",
       "       'subject_of_expertise=Biology', 'subject_of_expertise=Chemistry',\n",
       "       'subject_of_expertise=Computer_sciences',\n",
       "       'subject_of_expertise=Culinary_arts',\n",
       "       'subject_of_expertise=Earth_sciences', 'subject_of_expertise=Economics',\n",
       "       'subject_of_expertise=Electrical_engineering',\n",
       "       'subject_of_expertise=Environmental_studies_and_forestry',\n",
       "       'subject_of_expertise=Family_and_consumer_science',\n",
       "       'subject_of_expertise=Geography', 'subject_of_expertise=History',\n",
       "       'subject_of_expertise=Human_physical_performance_and_recreation',\n",
       "       'subject_of_expertise=Journalism',\n",
       "       'subject_of_expertise=Linguistics_and_language',\n",
       "       'subject_of_expertise=Literature', 'subject_of_expertise=Logic',\n",
       "       'subject_of_expertise=Materials_science_and_engineering',\n",
       "       'subject_of_expertise=Medicine_and_health',\n",
       "       'subject_of_expertise=Others', 'subject_of_expertise=Performing_arts',\n",
       "       'subject_of_expertise=Philosophy', 'subject_of_expertise=Physics',\n",
       "       'subject_of_expertise=Political_science',\n",
       "       'subject_of_expertise=Psychology',\n",
       "       'subject_of_expertise=Public_administration',\n",
       "       'subject_of_expertise=Religion', 'subject_of_expertise=Social_work',\n",
       "       'subject_of_expertise=Sociology', 'subject_of_expertise=Space_sciences',\n",
       "       'subject_of_expertise=System_science',\n",
       "       'subject_of_expertise=Visual_arts', 'type_of_in_context_material=1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial LightGBM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ratio_df.drop(columns=[\"hash\", \"Overall\", \"label\"])\n",
    "y = ratio_df[\"Overall\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16\n",
      "[LightGBM] [Info] Number of data points in the train set: 127, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 0.686147\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Mean Squared Error: 0.00037589768804514254\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"mse\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_leaves\": 31,\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "model = lgb.train(params, train_data, valid_sets=[test_data])\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Feature  Importance\n",
      "3                                          entity_sim    0.035810\n",
      "54                      type_of_in_context_material=1    0.035582\n",
      "12                                  languages=English    0.009497\n",
      "2                                          cosine_sim    0.008946\n",
      "11                               format_constraints=1    0.002425\n",
      "4                                    bertscore_length    0.001839\n",
      "0                                               rouge    0.000101\n",
      "7                        complexity_of_intents=simple    0.000000\n",
      "8              expertise_level=basic_domain_knowledge    0.000000\n",
      "33                       subject_of_expertise=History    0.000000\n",
      "34  subject_of_expertise=Human_physical_performanc...    0.000000\n",
      "35                    subject_of_expertise=Journalism    0.000000\n",
      "36      subject_of_expertise=Linguistics_and_language    0.000000\n",
      "37                    subject_of_expertise=Literature    0.000000\n",
      "38                         subject_of_expertise=Logic    0.000000\n",
      "39  subject_of_expertise=Materials_science_and_eng...    0.000000\n",
      "40           subject_of_expertise=Medicine_and_health    0.000000\n",
      "41                        subject_of_expertise=Others    0.000000\n",
      "42               subject_of_expertise=Performing_arts    0.000000\n",
      "43                    subject_of_expertise=Philosophy    0.000000\n",
      "44                       subject_of_expertise=Physics    0.000000\n",
      "45             subject_of_expertise=Political_science    0.000000\n",
      "46                    subject_of_expertise=Psychology    0.000000\n",
      "47         subject_of_expertise=Public_administration    0.000000\n",
      "48                      subject_of_expertise=Religion    0.000000\n",
      "49                   subject_of_expertise=Social_work    0.000000\n",
      "50                     subject_of_expertise=Sociology    0.000000\n",
      "51                subject_of_expertise=Space_sciences    0.000000\n",
      "52                subject_of_expertise=System_science    0.000000\n",
      "53                   subject_of_expertise=Visual_arts    0.000000\n",
      "32                     subject_of_expertise=Geography    0.000000\n",
      "31   subject_of_expertise=Family_and_consumer_science    0.000000\n",
      "30  subject_of_expertise=Environmental_studies_and...    0.000000\n",
      "18                                 safety_concern=low    0.000000\n",
      "9             expertise_level=expert_domain_knowledge    0.000000\n",
      "10                     expertise_level=general_public    0.000000\n",
      "6                      complexity_of_intents=moderate    0.000000\n",
      "5                       complexity_of_intents=complex    0.000000\n",
      "13                                open_endedness=high    0.000000\n",
      "14                                 open_endedness=low    0.000000\n",
      "15                            open_endedness=moderate    0.000000\n",
      "16                                  open_endedness=no    0.000000\n",
      "17                                safety_concern=high    0.000000\n",
      "19                            safety_concern=moderate    0.000000\n",
      "29        subject_of_expertise=Electrical_engineering    0.000000\n",
      "20                                safety_concern=safe    0.000000\n",
      "21                   subject_of_expertise=Agriculture    0.000000\n",
      "22                  subject_of_expertise=Anthropology    0.000000\n",
      "23                       subject_of_expertise=Biology    0.000000\n",
      "24                     subject_of_expertise=Chemistry    0.000000\n",
      "25             subject_of_expertise=Computer_sciences    0.000000\n",
      "26                 subject_of_expertise=Culinary_arts    0.000000\n",
      "1                                           bertscore    0.000000\n",
      "28                     subject_of_expertise=Economics    0.000000\n",
      "27                subject_of_expertise=Earth_sciences    0.000000\n"
     ]
    }
   ],
   "source": [
    "importances = model.feature_importance(importance_type=\"gain\")  # or 'gain'\n",
    "\n",
    "# Create a DataFrame to view feature importances\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {\"Feature\": X.columns, \"Importance\": importances}\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
