{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "from ast import literal_eval\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "\n",
    "from src.utils import find_meta_category\n",
    "from src.feature_extractor import sample_feature_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download prerequisite files\n",
    "\n",
    "Fetch all the results and feature values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching experiments list...\n",
      "Downloading dataset \u001b[36m01J6KF3JRCATRJQ9CPJTRV5VBM\u001b[0m to \u001b[32m.\u001b[0m\n",
      "Files: 0          ⠋  \n",
      "Bytes: 0 B        ⠋  \n",
      "\u001b[2A\u001b[JFiles: 1          ⠙  \n",
      "Bytes: 73.77 KiB  ⠙  \n",
      "\u001b[2A\u001b[JFiles: 1          ✔  \n",
      "Bytes: 73.77 KiB  ✔  \n",
      "\u001b[2A\u001b[JFiles: 1          ✔  \n",
      "Bytes: 73.77 KiB  ✔  \n",
      "Completed in 100ms: 506.3 KiB/s, 7 files/s\n",
      "Fetching extracted features...\n",
      "mkdir: features/: File exists\n",
      "Downloading dataset \u001b[36m01J6KF3JRCATRJQ9CPJTRV5VBM\u001b[0m to \u001b[32m.\u001b[0m\n",
      "Files: 0          ⠋  \n",
      "Bytes: 0 B        ⠋  \n",
      "\u001b[2A\u001b[JFiles: 5          ⠙  \n",
      "Bytes: 188.1 MiB  ⠙  \n",
      "\u001b[2A\u001b[JFiles: 11         ⠹  \n",
      "Bytes: 414.3 MiB  ⠹  \n",
      "\u001b[2A\u001b[JFiles: 16         ⠸  \n",
      "Bytes: 602.9 MiB  ⠸  \n",
      "\u001b[2A\u001b[JFiles: 16         ✔  \n",
      "Bytes: 602.9 MiB  ✔  \n",
      "\u001b[2A\u001b[JFiles: 16         ✔  \n",
      "Bytes: 602.9 MiB  ✔  \n",
      "Completed in 400ms: 1.347 GiB/s, 37 files/s\n",
      "Fetching helpsteer2 dataset\n",
      "Downloading dataset \u001b[36m01J6KBM2VCM9EQ7MER26VBXCCM\u001b[0m to \u001b[32m.\u001b[0m\n",
      "Files: 0          ⠋  \n",
      "Bytes: 0 B        ⠋  \n",
      "\u001b[2A\u001b[JFiles: 1          ⠙  \n",
      "Bytes: 70.58 MiB  ⠙  \n",
      "\u001b[2A\u001b[JFiles: 1          ✔  \n",
      "Bytes: 70.58 MiB  ✔  \n",
      "\u001b[2A\u001b[JFiles: 1          ✔  \n",
      "Bytes: 70.58 MiB  ✔  \n",
      "Completed in 100ms: 388.6 MiB/s, 6 files/s\n",
      "Collating all evaluation results\n",
      "2024-09-02 13:19:09 - INFO - root - Logged-in as ljm (ljm@allenai.org)\n",
      "2024-09-02 13:19:09 - INFO - root - Found 195 experiments that match 'rm-eval-helpsteer2'\n",
      "2024-09-02 13:19:31 - INFO - root - Computing category scores...\n",
      "2024-09-02 13:19:31 - INFO - root - Deriving features from the experiments file: experiments.txt\n",
      "2024-09-02 13:19:31 - INFO - root - Will attempt merge via feature hash\n",
      "2024-09-02 13:19:31 - INFO - root - Creating labels in column 'label' with GPT-4 threshold '0.658'\n",
      "2024-09-02 13:19:31 - INFO - root - Saving 63 results to results.csv\n",
      "2024-09-02 13:19:31 - INFO - root - Saved on results.csv\n"
     ]
    }
   ],
   "source": [
    "# You can get the experiments file here: 01J6KF3JRCATRJQ9CPJTRV5VBM (https://beaker.org/ds/01J6KF3JRCATRJQ9CPJTRV5VBM/details)\n",
    "!echo \"Fetching experiments list...\"\n",
    "!beaker dataset fetch 01J6KF3JRCATRJQ9CPJTRV5VBM --prefix experiments.txt\n",
    "!echo \"Fetching extracted features...\"\n",
    "!mkdir features/\n",
    "!beaker dataset fetch 01J6KF3JRCATRJQ9CPJTRV5VBM --prefix features/ \n",
    "#!beaker dataset fetch 01J6KFVCRCTYHCZDR0XNK0G9HT --prefix features/\n",
    "!echo \"Fetching helpsteer2 dataset\"\n",
    "!beaker dataset fetch 01J6KBM2VCM9EQ7MER26VBXCCM\n",
    "!echo \"Collating all evaluation results\"\n",
    "%run ../../scripts/fetch_evals_rewardbench.py --output_file results.csv --gpt4_threshold_score 0.658 --experiment_prefix rm-eval-helpsteer2 --experiments_file experiments.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collate feature set for all instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEXICAL_FEATS_PATH = Path(\"features\")\n",
    "DATASET_PATH = Path(\"helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl\")\n",
    "\n",
    "\n",
    "def get_dataset_features(\n",
    "    feature_path=LEXICAL_FEATS_PATH, dataset_path=DATASET_PATH\n",
    ") -> \"pd.DataFrame\":\n",
    "    lexical_features = [\n",
    "        \"rouge\",\n",
    "        \"bertscore\",\n",
    "        \"bertscore_length\",\n",
    "        \"entity_sim\",\n",
    "        \"cosine_sim\",\n",
    "        \"prompt_len\",\n",
    "        \"len_longer\",\n",
    "        \"len_shorter\",\n",
    "        \"token_len_difference\",\n",
    "    ]\n",
    "    lexical_feature_files = [\n",
    "        file\n",
    "        for file in feature_path.glob(\"*.jsonl\")\n",
    "        if any(file.stem in feat for feat in lexical_features)\n",
    "    ]\n",
    "    lexical_feats_df = reduce(\n",
    "        lambda left, right: left.merge(\n",
    "            right, on=[\"id\", \"prompt\", \"completion_a\", \"completion_b\"], how=\"outer\"\n",
    "        ),\n",
    "        [pd.read_json(file, lines=True) for file in lexical_feature_files],\n",
    "    )\n",
    "\n",
    "    df = pd.read_json(dataset_path, lines=True).rename(columns={\"prompt_hash\": \"id\"})\n",
    "    finaldf = df.merge(lexical_feats_df, how=\"left\", on=\"id\").drop(\n",
    "        columns=[\"prompt\", \"completion_a\", \"completion_b\"]\n",
    "    )\n",
    "\n",
    "    # Hacky way for token_len_difference\n",
    "    finaldf = finaldf.rename(columns={\"token_len_diff\": \"token_len_difference\"})\n",
    "    return finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.read_csv(\"results.csv\").dropna()\n",
    "features_df = get_dataset_features()\n",
    "print(len(results_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get proportion of instances that fulfill the conditions\n",
    "\n",
    "1. For each row, get features that were activated\n",
    "2. Then for each activated feature, we get the proportion by looking at the feature dataframe.\n",
    "3. The proportion is computed as: `number_of_instance_that_fulfill_a_single_condition` / `total_number_of_instances`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expertise_level</th>\n",
       "      <th>format_constraints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>expert domain knowledge</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4613</th>\n",
       "      <td>basic domain knowledge</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>general public</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              expertise_level format_constraints\n",
       "289                      None                 []\n",
       "1317  expert domain knowledge               None\n",
       "4613   basic domain knowledge               None\n",
       "4734           general public               None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect nan columns\n",
    "rows_with_nan = features_df[features_df.isna().any(axis=1)]\n",
    "nan_columns = rows_with_nan.columns[rows_with_nan.isna().any()]\n",
    "df_nan_columns = rows_with_nan[nan_columns]\n",
    "df_nan_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what you're going to do instead, is to take the binary_cols, and then for each element of that binary_cols, you compute the \"weight\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_instances(feat: str, features_df: \"pd.DataFrame\") -> float:\n",
    "    total = len(features_df)\n",
    "    lexical_features = [\n",
    "        \"rouge\",\n",
    "        \"bertscore\",\n",
    "        \"bertscore_length\",\n",
    "        \"entity_sim\",\n",
    "        \"cosine_sim\",\n",
    "        \"prompt_len\",\n",
    "        \"len_longer\",\n",
    "        \"len_shorter\",\n",
    "        \"token_len_difference\",\n",
    "    ]\n",
    "\n",
    "    if feat.split(\"__\")[0] in lexical_features:\n",
    "        feat_name, value = feat.split(\"__\")\n",
    "        min_val_str, max_val_str = value.split(\"|\")\n",
    "        min_val, max_val = float(min_val_str.split(\"=\")[1]), float(\n",
    "            max_val_str.split(\"=\")[1]\n",
    "        )\n",
    "        return features_df[feat_name].between(min_val, max_val).mean()\n",
    "    else:\n",
    "        # Parse the feature\n",
    "        feat_name, value = feat.split(\"=\")\n",
    "        meta_category = find_meta_category(feat_name)\n",
    "        if meta_category == \"scalar\":\n",
    "            v = value.replace(\"_\", \" \")\n",
    "            return features_df[feat_name].value_counts().get(v) / total\n",
    "        elif meta_category == \"closed_set\":\n",
    "            v = value.replace(\"_\", \" \")\n",
    "            list_of_values = features_df[feat_name].tolist()\n",
    "            return sum([1 if v in listval else 0 for listval in list_of_values]) / total\n",
    "        elif meta_category == \"open_set\":\n",
    "            list_of_values = features_df[feat_name].tolist()\n",
    "            return sum([1 if listval else 0 for listval in list_of_values]) / total\n",
    "\n",
    "        return find_meta_category(feat_name)\n",
    "\n",
    "\n",
    "feats = results_df.columns[results_df.isin([0, 1]).all()]  # get binary columns\n",
    "feat_map = {\n",
    "    feat: compute_instances(feat, features_df) for feat in feats if feat != \"label\"\n",
    "}\n",
    "\n",
    "ratio_df = results_df.apply(\n",
    "    lambda row: row.map(lambda x: feat_map.get(row.name, 1) if x == 1 else x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LightGBM regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 56, test size: 7\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 56, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 0.695507\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Mean Squared Error: 0.0014471947901713886\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"mse\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_leaves\": 31,\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "binary = False\n",
    "X = ratio_df[list(feat_map.keys())]\n",
    "if binary:\n",
    "    X = (X > 0).astype(int)\n",
    "y = ratio_df[\"Overall\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42\n",
    ")\n",
    "print(f\"Train size: {len(X_train)}, test size: {len(X_test)}\")\n",
    "\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "model = lgb.train(params, train_data, valid_sets=[test_data])\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Feature  Importance\n",
      "0    bertscore__min_val=0.33|max_val=0.67         0.0\n",
      "33       rouge__min_val=0.33|max_val=0.67         0.0\n",
      "35                    safety_concern=high         0.0\n",
      "36                     safety_concern=low         0.0\n",
      "37                safety_concern=moderate         0.0\n",
      "..                                    ...         ...\n",
      "27                open_endedness=moderate         0.0\n",
      "28                      open_endedness=no         0.0\n",
      "29   prompt_len__min_val=0.0|max_val=0.33         0.0\n",
      "30  prompt_len__min_val=0.33|max_val=0.67         0.0\n",
      "64          type_of_in_context_material=1         0.0\n",
      "\n",
      "[65 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "importances = model.feature_importance(importance_type=\"gain\")  # ['split', 'gain']\n",
    "\n",
    "# Create a DataFrame to view feature importances\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {\"Feature\": X.columns, \"Importance\": importances}\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LinearRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 50, test size: 13\n",
      "Feature names: ['bertscore__min_val=0.33|max_val=0.67'\n",
      " 'bertscore__min_val=0.67|max_val=1.0'\n",
      " 'bertscore_length__min_val=0.0|max_val=0.33' ...\n",
      " 'token_len_difference__min_val=0.67|max_val=1.0^2'\n",
      " 'token_len_difference__min_val=0.67|max_val=1.0 type_of_in_context_material=1'\n",
      " 'type_of_in_context_material=1^2']\n",
      "Mean Squared Error: 0.0014802672071204408\n",
      "Coeeficients: [-5.02407096e-01  2.53633436e-02  7.36212187e-02 ...  2.11200346e-03\n",
      "  0.00000000e+00 -2.47356076e-04]\n",
      "Intercept: 0.7162501458811744\n"
     ]
    }
   ],
   "source": [
    "polyfit = True\n",
    "binary = False\n",
    "\n",
    "X = ratio_df[list(feat_map.keys())]\n",
    "y = ratio_df[\"Overall\"]\n",
    "if binary:\n",
    "    X = (X > 0).astype(int)\n",
    "\n",
    "if polyfit:\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_poly, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, test size: {len(X_test)}\")\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Feature names: {poly.get_feature_names_out(X.columns)}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Coeeficients: {model.coef_}\")\n",
    "print(f\"Intercept: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance is not possible with polynomial features (hard to interpret)\n"
     ]
    }
   ],
   "source": [
    "if not polyfit:\n",
    "    feature_importance = pd.DataFrame(\n",
    "        {\"Feature\": X.columns, \"Coefficient\": model.coef_}\n",
    "    )\n",
    "\n",
    "    # Calculate absolute importance for easier comparison\n",
    "    feature_importance[\"Absolute_Coefficient\"] = np.abs(\n",
    "        feature_importance[\"Coefficient\"]\n",
    "    )\n",
    "\n",
    "    # Sort by absolute coefficient value\n",
    "    feature_importance = feature_importance.sort_values(\n",
    "        by=\"Absolute_Coefficient\", ascending=False\n",
    "    )\n",
    "    feature_importance.head(10)\n",
    "else:\n",
    "    print(\n",
    "        \"Feature importance is not possible with polynomial features (hard to interpret)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 45294.86it/s]\n",
      "45it [00:00, 62168.54it/s]\n",
      "120it [00:00, 74909.43it/s]\n",
      "210it [00:00, 57678.20it/s]\n",
      "252it [00:00, 49594.81it/s]\n",
      "210it [00:00, 43050.04it/s]\n",
      "120it [00:00, 34962.25it/s]\n",
      "45it [00:00, 31248.95it/s]\n",
      "10it [00:00, 23250.02it/s]\n",
      "1it [00:00, 7869.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-02 13:19:34 - INFO - root - Adding meta analyzer features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [00:00, 108660.73it/s]\n",
      "45it [00:00, 106095.38it/s]\n",
      "120it [00:00, 75812.09it/s]\n",
      "210it [00:00, 63886.55it/s]\n",
      "252it [00:00, 54125.59it/s]\n",
      "210it [00:00, 44512.02it/s]\n",
      "120it [00:00, 36900.04it/s]\n",
      "45it [00:00, 4900.91it/s]\n",
      "10it [00:00, 7147.76it/s]\n",
      "1it [00:00, 938.95it/s]\n"
     ]
    }
   ],
   "source": [
    "_, combinations = sample_feature_combinations(\n",
    "    meta_analyzer_n_samples=2000, max_number=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/gk2rs0792pn5p8hkj4nkhdm80000gp/T/ipykernel_42490/4023816742.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx, combination in tqdm_notebook(enumerate(combinations), total=len(combinations)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d2f1a300234fdf898e4accc640040a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4069 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim_df = pd.DataFrame(0, index=np.arange(len(combinations)), columns=X.columns)\n",
    "for idx, combination in tqdm_notebook(enumerate(combinations), total=len(combinations)):\n",
    "    activated_feats = []\n",
    "    for feat in combination:\n",
    "        if \"analyzer\" in feat:\n",
    "            feature_name_str, value_str = feat.split(\"::\")[1].split(\"|\")\n",
    "            feature_name, value = (\n",
    "                feature_name_str.split(\"=\")[-1],\n",
    "                value_str.split(\"=\")[-1],\n",
    "            )\n",
    "            activated_feats.append(f\"{feature_name}={value}\")\n",
    "        else:\n",
    "            activated_feats.append(feat.replace(\"::\", \"__\"))\n",
    "    sim_df.loc[idx, activated_feats] = 1\n",
    "sim_df = sim_df.apply(\n",
    "    lambda row: row.map(lambda x: feat_map.get(row.name, 1) if x == 1 else x)\n",
    ").dropna(axis=1, how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activated_features</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[bertscore_length__min_val=0.33|max_val=0.67, ...</td>\n",
       "      <td>0.822932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[bertscore_length__min_val=0.33|max_val=0.67, ...</td>\n",
       "      <td>0.822932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bertscore_length__min_val=0.33|max_val=0.67, ...</td>\n",
       "      <td>0.801309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[bertscore_length__min_val=0.33|max_val=0.67, ...</td>\n",
       "      <td>0.798901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[bertscore_length__min_val=0.33|max_val=0.67, ...</td>\n",
       "      <td>0.798901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[bertscore_length__min_val=0.33|max_val=0.67, ...</td>\n",
       "      <td>0.798842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[complexity_of_intents=simple, open_endedness=...</td>\n",
       "      <td>0.796861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[complexity_of_intents=simple, safety_concern=...</td>\n",
       "      <td>0.795569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[complexity_of_intents=simple, safety_concern=...</td>\n",
       "      <td>0.794779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[complexity_of_intents=simple, open_endedness=...</td>\n",
       "      <td>0.794749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[bertscore__min_val=0.67|max_val=1.0, bertscor...</td>\n",
       "      <td>0.792170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[bertscore__min_val=0.67|max_val=1.0, bertscor...</td>\n",
       "      <td>0.792118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[bertscore__min_val=0.67|max_val=1.0, complexi...</td>\n",
       "      <td>0.789859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[bertscore_length__min_val=0.67|max_val=1.0, r...</td>\n",
       "      <td>0.789605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[bertscore_length__min_val=0.0|max_val=0.33, c...</td>\n",
       "      <td>0.788220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[bertscore__min_val=0.67|max_val=1.0, rouge__m...</td>\n",
       "      <td>0.785854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[bertscore__min_val=0.67|max_val=1.0, rouge__m...</td>\n",
       "      <td>0.785854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[bertscore_length__min_val=0.33|max_val=0.67, ...</td>\n",
       "      <td>0.785726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[bertscore__min_val=0.67|max_val=1.0, len_shor...</td>\n",
       "      <td>0.785640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[bertscore__min_val=0.33|max_val=0.67, bertsco...</td>\n",
       "      <td>0.785044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   activated_features      pred\n",
       "0   [bertscore_length__min_val=0.33|max_val=0.67, ...  0.822932\n",
       "1   [bertscore_length__min_val=0.33|max_val=0.67, ...  0.822932\n",
       "2   [bertscore_length__min_val=0.33|max_val=0.67, ...  0.801309\n",
       "3   [bertscore_length__min_val=0.33|max_val=0.67, ...  0.798901\n",
       "4   [bertscore_length__min_val=0.33|max_val=0.67, ...  0.798901\n",
       "5   [bertscore_length__min_val=0.33|max_val=0.67, ...  0.798842\n",
       "6   [complexity_of_intents=simple, open_endedness=...  0.796861\n",
       "7   [complexity_of_intents=simple, safety_concern=...  0.795569\n",
       "8   [complexity_of_intents=simple, safety_concern=...  0.794779\n",
       "9   [complexity_of_intents=simple, open_endedness=...  0.794749\n",
       "10  [bertscore__min_val=0.67|max_val=1.0, bertscor...  0.792170\n",
       "11  [bertscore__min_val=0.67|max_val=1.0, bertscor...  0.792118\n",
       "12  [bertscore__min_val=0.67|max_val=1.0, complexi...  0.789859\n",
       "13  [bertscore_length__min_val=0.67|max_val=1.0, r...  0.789605\n",
       "14  [bertscore_length__min_val=0.0|max_val=0.33, c...  0.788220\n",
       "15  [bertscore__min_val=0.67|max_val=1.0, rouge__m...  0.785854\n",
       "16  [bertscore__min_val=0.67|max_val=1.0, rouge__m...  0.785854\n",
       "17  [bertscore_length__min_val=0.33|max_val=0.67, ...  0.785726\n",
       "18  [bertscore__min_val=0.67|max_val=1.0, len_shor...  0.785640\n",
       "19  [bertscore__min_val=0.33|max_val=0.67, bertsco...  0.785044"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_results = sim_df.copy(deep=True)\n",
    "sim_results[\"activated_features\"] = sim_results.apply(\n",
    "    lambda row: [col for col in sim_results.columns if row[col] != 0], axis=1\n",
    ")\n",
    "sim_results[\"pred\"] = model.predict(poly.transform(sim_df))\n",
    "sim_results = sim_results.sort_values(by=\"pred\", ascending=False).reset_index(drop=True)\n",
    "sim_results[[\"activated_features\", \"pred\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bertscore_length__min_val=0.33|max_val=0.67', 'cosine_sim__min_val=0.67|max_val=1.0', 'entity_sim__min_val=0.0|max_val=0.33', 'rouge__min_val=0.0|max_val=0.33', 'token_len_difference__min_val=0.67|max_val=1.0'], ['bertscore_length__min_val=0.33|max_val=0.67', 'cosine_sim__min_val=0.67|max_val=1.0', 'entity_sim__min_val=0.0|max_val=0.33', 'rouge__min_val=0.0|max_val=0.33', 'token_len_difference__min_val=0.67|max_val=1.0'], ['bertscore_length__min_val=0.33|max_val=0.67', 'cosine_sim__min_val=0.67|max_val=1.0', 'entity_sim__min_val=0.0|max_val=0.33', 'token_len_difference__min_val=0.67|max_val=1.0'], ['bertscore_length__min_val=0.33|max_val=0.67', 'cosine_sim__min_val=0.67|max_val=1.0', 'entity_sim__min_val=0.0|max_val=0.33', 'open_endedness=high', 'prompt_len__min_val=0.67|max_val=1.0'], ['bertscore_length__min_val=0.33|max_val=0.67', 'cosine_sim__min_val=0.67|max_val=1.0', 'entity_sim__min_val=0.0|max_val=0.33', 'prompt_len__min_val=0.67|max_val=1.0'], ['bertscore_length__min_val=0.33|max_val=0.67', 'cosine_sim__min_val=0.67|max_val=1.0', 'entity_sim__min_val=0.0|max_val=0.33'], ['complexity_of_intents=simple', 'open_endedness=no', 'safety_concern=safe', 'token_len_difference__min_val=0.67|max_val=1.0', 'type_of_in_context_material=1'], ['complexity_of_intents=simple', 'safety_concern=safe'], ['complexity_of_intents=simple', 'safety_concern=safe', 'subject_of_expertise=Literature', 'type_of_in_context_material=1'], ['complexity_of_intents=simple', 'open_endedness=no', 'safety_concern=safe', 'subject_of_expertise=Sociology', 'type_of_in_context_material=1']]\n"
     ]
    }
   ],
   "source": [
    "top_combinations = sim_results.activated_features.head(10).to_list()\n",
    "print(top_combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: So now you have determined 10 feature combinations that seem to work well. The next step is to train RMs and evaluate them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beaker import Beaker, ExperimentSpec\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = ExperimentSpec.from_file(\"../../beaker/template.yml\")\n",
    "exp_spec = deepcopy(spec)\n",
    "template_task = exp_spec.tasks.pop(0)\n",
    "\n",
    "new_tasks = []\n",
    "for idx, combination in enumerate(top_combinations):\n",
    "    feats_to_run = []\n",
    "    for feat in combination:\n",
    "        if \"min_val\" in feat:\n",
    "            if \"token_len_difference\" in feat:\n",
    "                feat = feat.replace(\"difference\", \"diff\")\n",
    "            feats_to_run.append(feat.replace(\"__\", \"::\"))\n",
    "        else:\n",
    "            feat_name, value = feat.split(\"=\")\n",
    "            category = find_meta_category(feat_name)\n",
    "            if category == \"closed_set\":\n",
    "                key = \"constraints\"\n",
    "            elif category == \"scalar\":\n",
    "                key = \"value\"\n",
    "            elif category == \"open_set\":\n",
    "                key = \"check_for_existence\"\n",
    "            feats_to_run.append(f\"{category}::feature_name={feat_name}|{key}={value}\")\n",
    "    # Create beaker task\n",
    "    task = deepcopy(template_task)\n",
    "    task.name = f\"get-features-datamodel-{idx}\"\n",
    "    task.arguments.extend([\"--features\"] + feats_to_run)\n",
    "    new_tasks.append(task)\n",
    "\n",
    "exp_spec.tasks = new_tasks\n",
    "exp_spec.validate()\n",
    "exp_spec.to_file(\"experiments.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get finished jobs and download the subsets and create an `experiments.txt` file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_subsets_dir = Path(\"top_n_subsets\")\n",
    "top_subsets_dir.mkdir(parents=True, exist_ok=True)\n",
    "experiments_file = top_subsets_dir / \"top_n_subsets_experiments.txt\"\n",
    "beaker = Beaker.from_env(\"ai2/ljm-oe-adapt\")\n",
    "experiment = beaker.experiment.get(\"01J6T8J4DC8PDTE5AT7NCJE8X6\")\n",
    "for job in experiment.jobs:\n",
    "    if job.is_done:\n",
    "        # Get output\n",
    "        dataset_id = job.execution.result.beaker\n",
    "        beaker.dataset.fetch(\n",
    "            dataset_id,\n",
    "            force=True,\n",
    "            target=top_subsets_dir,\n",
    "            prefix=\"data/\",\n",
    "            quiet=True,\n",
    "        )\n",
    "\n",
    "        beaker.dataset.fetch(\n",
    "            dataset_id,\n",
    "            force=True,\n",
    "            target=top_subsets_dir,\n",
    "            prefix=\"experiments.txt\",\n",
    "            quiet=True,\n",
    "        )\n",
    "\n",
    "        with open(top_subsets_dir / \"experiments.txt\", \"r\") as f:\n",
    "            data = f.read().splitlines()\n",
    "            id = data[0]\n",
    "\n",
    "        with open(experiments_file, \"a\") as f:\n",
    "            f.write(id + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExecutionResult(beaker='01J6T8J4RZN16TTPCFT1RXJZYW')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbeaker.experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experiment(id='01J6T8J4DC8PDTE5AT7NCJE8X6', name=None, full_name=None, description='Get features using datamodel approach', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, workspace_ref=WorkspaceRef(id='01HPMTGH3Z5P5AF1NVJ2W7B6KR', name='ljm-oe-adapt', full_name='ai2/ljm-oe-adapt'), jobs=(Job(id='01J6T8J4JDYQJ3REARYYVYBW8S', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 21, 2, 21, 312990, tzinfo=TzInfo(UTC)), exited=None, failed=None, finalized=None, canceled=None, canceled_for=None, canceled_code=None, idle_since=None, ready=datetime.datetime(2024, 9, 2, 21, 2, 16, 760085, tzinfo=TzInfo(UTC)), exit_code=None, message=None), name='get-features-datamodel-0', cluster=None, execution=JobExecution(task='01J6T8J4DH0WZF4SN48XQWM6EM', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-0', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'bertscore_length::min_val=0.33|max_val=0.67', 'cosine_sim::min_val=0.67|max_val=1.0', 'entity_sim::min_val=0.0|max_val=0.33', 'rouge::min_val=0.0|max_val=0.33', 'token_len_diff::min_val=0.67|max_val=1.0'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J4JDYQJ3REARYYVYBW8S', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01GTJAB9KQBFKSWTKVYPTAW97Z', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-50.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J4DH0WZF4SN48XQWM6EM', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='31', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J4EX7WJP3W3EB36ADDXR', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J4EX7WJP3W3EB36ADDXR'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01GTJAB9KQBFKSWTKVYPTAW97Z', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=31.0, memory=None, gpus=('GPU-0b766d18-9021-0813-f0e6-079c3ca46da7', 'GPU-59671ece-e605-9320-2825-4921e70b835e')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J4EX7WJP3W3EB36ADDXR'), preemptible=True), Job(id='01J6T8J4QE1X9R6AWW4NXTBXQQ', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 21, 2, 21, 311585, tzinfo=TzInfo(UTC)), exited=None, failed=None, finalized=None, canceled=None, canceled_for=None, canceled_code=None, idle_since=None, ready=datetime.datetime(2024, 9, 2, 21, 2, 16, 759997, tzinfo=TzInfo(UTC)), exit_code=None, message=None), name='get-features-datamodel-1', cluster=None, execution=JobExecution(task='01J6T8J4JKNRV85MJWJ0YFGR3V', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-1', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'bertscore_length::min_val=0.33|max_val=0.67', 'cosine_sim::min_val=0.67|max_val=1.0', 'entity_sim::min_val=0.0|max_val=0.33', 'rouge::min_val=0.0|max_val=0.33', 'token_len_diff::min_val=0.67|max_val=1.0'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J4QE1X9R6AWW4NXTBXQQ', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01GTJAB9KQBFKSWTKVYPTAW97Z', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-50.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J4JKNRV85MJWJ0YFGR3V', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='31', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J4KYW8XPB95NNQJ1EGHE', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J4KYW8XPB95NNQJ1EGHE'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01GTJAB9KQBFKSWTKVYPTAW97Z', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=31.0, memory=None, gpus=('GPU-f17000b0-6b5a-5954-1cd8-14aec898cb09', 'GPU-86b88a9c-569e-36d8-4784-bff425248ae1')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J4KYW8XPB95NNQJ1EGHE'), preemptible=True), Job(id='01J6T8J4WAHKY9N3PXT6EBSQS0', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 45, 888643, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 21, 7, 50, 10227, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 21, 8, 0, 673274, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 21, 7, 49, 942219, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 45, 146555, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-2', cluster=None, execution=JobExecution(task='01J6T8J4QN0ECMN97KM99KAF4Z', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-2', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'bertscore_length::min_val=0.33|max_val=0.67', 'cosine_sim::min_val=0.67|max_val=1.0', 'entity_sim::min_val=0.0|max_val=0.33', 'token_len_diff::min_val=0.67|max_val=1.0'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J4WAHKY9N3PXT6EBSQS0', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01J1QQSRH28MAMC5HKW4W87W1M', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='jupiter-cs-aus-219.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J4QN0ECMN97KM99KAF4Z', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='46.5', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J4RZN16TTPCFT1RXJZYW', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J4RZN16TTPCFT1RXJZYW'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01J1QQSRH28MAMC5HKW4W87W1M', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=46.5, memory=None, gpus=('GPU-6b0d84b9-d255-572f-c67a-09603f286127', 'GPU-d863315a-ed74-044c-1387-322ff0c09b5f')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J4RZN16TTPCFT1RXJZYW'), preemptible=True), Job(id='01J6T8J51CR3H4VJSZ0YTV827D', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 45, 428571, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 21, 7, 46, 895027, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 21, 7, 58, 475740, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 21, 7, 46, 741499, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 44, 643580, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-3', cluster=None, execution=JobExecution(task='01J6T8J4WHKVT8DZ2W5XAKQX9Z', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-3', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'bertscore_length::min_val=0.33|max_val=0.67', 'cosine_sim::min_val=0.67|max_val=1.0', 'entity_sim::min_val=0.0|max_val=0.33', 'scalar::feature_name=open_endedness|value=high', 'prompt_len::min_val=0.67|max_val=1.0'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J51CR3H4VJSZ0YTV827D', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01J1QQSRH28MAMC5HKW4W87W1M', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='jupiter-cs-aus-219.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J4WHKVT8DZ2W5XAKQX9Z', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='46.5', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J4XVTZFXYV6F0NBPJ4TY', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J4XVTZFXYV6F0NBPJ4TY'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01J1QQSRH28MAMC5HKW4W87W1M', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=46.5, memory=None, gpus=('GPU-19ccfe32-1d10-e652-d8a2-fc456ed9f853', 'GPU-884ba3d1-46f6-0b84-d39d-03dc96606a8b')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J4XVTZFXYV6F0NBPJ4TY'), preemptible=True), Job(id='01J6T8J56B52X1FWGP5RNQKJAT', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 45, 982994, tzinfo=TzInfo(UTC)), exited=None, failed=None, finalized=None, canceled=None, canceled_for=None, canceled_code=None, idle_since=None, ready=datetime.datetime(2024, 9, 2, 20, 59, 44, 864911, tzinfo=TzInfo(UTC)), exit_code=None, message=None), name='get-features-datamodel-4', cluster=None, execution=JobExecution(task='01J6T8J51K6EFBH0V86HCK62V6', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-4', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'bertscore_length::min_val=0.33|max_val=0.67', 'cosine_sim::min_val=0.67|max_val=1.0', 'entity_sim::min_val=0.0|max_val=0.33', 'prompt_len::min_val=0.67|max_val=1.0'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J56B52X1FWGP5RNQKJAT', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01GQHF8W7VTWHJCBRMK6CPMQPD', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-51.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J51K6EFBH0V86HCK62V6', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='23.25', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J52YHMS1WGVHFMKFBZ4Q', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J52YHMS1WGVHFMKFBZ4Q'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01GQHF8W7VTWHJCBRMK6CPMQPD', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=23.25, memory=None, gpus=('GPU-5c0a5e30-6d5c-516d-bf70-0aa12ef5f45b', 'GPU-62a22913-899f-d6c7-fa85-4f209d03fb2b')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J52YHMS1WGVHFMKFBZ4Q'), preemptible=True), Job(id='01J6T8J5BT7GPDVNMAG7MD8CN9', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 45, 565806, tzinfo=TzInfo(UTC)), exited=None, failed=None, finalized=None, canceled=None, canceled_for=None, canceled_code=None, idle_since=None, ready=datetime.datetime(2024, 9, 2, 20, 59, 44, 524769, tzinfo=TzInfo(UTC)), exit_code=None, message=None), name='get-features-datamodel-5', cluster=None, execution=JobExecution(task='01J6T8J56JNJ8J5RRM87Z029ER', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-5', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'bertscore_length::min_val=0.33|max_val=0.67', 'cosine_sim::min_val=0.67|max_val=1.0', 'entity_sim::min_val=0.0|max_val=0.33'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J5BT7GPDVNMAG7MD8CN9', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01GQHF8W7VTWHJCBRMK6CPMQPD', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-51.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J56JNJ8J5RRM87Z029ER', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='23.25', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J58A76W82WKMCBK8Y7BG', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J58A76W82WKMCBK8Y7BG'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01GQHF8W7VTWHJCBRMK6CPMQPD', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=23.25, memory=None, gpus=('GPU-b7acce8a-0aeb-48f1-49e7-36adeb4e0186', 'GPU-fc3efdee-1954-6d5f-79b0-0a60d48c3379')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J58A76W82WKMCBK8Y7BG'), preemptible=True), Job(id='01J6T8J5GPEAEWTEZ3FRVSDET2', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 43, 21794, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 21, 0, 20, 302117, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 21, 0, 23, 145600, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 21, 0, 20, 271581, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 41, 867351, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-6', cluster=None, execution=JobExecution(task='01J6T8J5C0CFA12F3ER6QRBPQ2', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-6', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'scalar::feature_name=complexity_of_intents|value=simple', 'scalar::feature_name=open_endedness|value=no', 'scalar::feature_name=safety_concern|value=safe', 'token_len_diff::min_val=0.67|max_val=1.0', 'open_set::feature_name=type_of_in_context_material|check_for_existence=1'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J5GPEAEWTEZ3FRVSDET2', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01HAAXJVZK8PKWEPZZE7JT1QKW', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-68.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J5C0CFA12F3ER6QRBPQ2', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='31', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J5DB8E2WM85CM43T6NS4', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J5DB8E2WM85CM43T6NS4'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01HAAXJVZK8PKWEPZZE7JT1QKW', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=31.0, memory=None, gpus=('GPU-05c4700c-b41c-a424-e4db-f75646533ce2', 'GPU-0b642c3c-0d0b-e891-953d-a8402e4a6a3b')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J5DB8E2WM85CM43T6NS4'), preemptible=True), Job(id='01J6T8J5P9RRSF6HNXCSZ6M5M7', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 42, 860262, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 20, 59, 51, 98874, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 20, 59, 51, 586852, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 20, 59, 51, 71016, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 41, 570045, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-7', cluster=None, execution=JobExecution(task='01J6T8J5GWHPQ1HCT3B6CVPZ88', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-7', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'scalar::feature_name=complexity_of_intents|value=simple', 'scalar::feature_name=safety_concern|value=safe'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J5P9RRSF6HNXCSZ6M5M7', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01HAAXJVZK8PKWEPZZE7JT1QKW', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-68.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J5GWHPQ1HCT3B6CVPZ88', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='31', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J5JDE51K6WKGEF5A9KNK', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J5JDE51K6WKGEF5A9KNK'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01HAAXJVZK8PKWEPZZE7JT1QKW', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=31.0, memory=None, gpus=('GPU-0fc76d68-bea2-abb1-66be-8d86c0c63e78', 'GPU-50bbab5a-c8dc-6d23-1d4d-f44506094e31')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J5JDE51K6WKGEF5A9KNK'), preemptible=True), Job(id='01J6T8J5VJSNJ0GDYT7D4M67RF', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 43, 596458, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 20, 59, 52, 107020, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 20, 59, 52, 598888, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 20, 59, 52, 78899, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 42, 380621, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-8', cluster=None, execution=JobExecution(task='01J6T8J5PHY6ZF899Q1ME47N8N', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-8', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'scalar::feature_name=complexity_of_intents|value=simple', 'scalar::feature_name=safety_concern|value=safe', 'closed_set::feature_name=subject_of_expertise|constraints=Literature', 'open_set::feature_name=type_of_in_context_material|check_for_existence=1'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J5VJSNJ0GDYT7D4M67RF', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01HAAXJVZK8PKWEPZZE7JT1QKW', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-68.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J5PHY6ZF899Q1ME47N8N', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='31', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J5R11SM2F2S7DPBSB3RN', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J5R11SM2F2S7DPBSB3RN'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01HAAXJVZK8PKWEPZZE7JT1QKW', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=31.0, memory=None, gpus=('GPU-d46323ef-46b4-12ca-0e6d-80606993c3ee', 'GPU-2a71f6b8-760f-2ffd-597e-18dc03093426')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J5R11SM2F2S7DPBSB3RN'), preemptible=True), Job(id='01J6T8J60JQJ136YV082P79QJW', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 42, 801772, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 20, 59, 48, 997820, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 20, 59, 49, 679428, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 20, 59, 48, 913565, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 42, 214032, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-9', cluster=None, execution=JobExecution(task='01J6T8J5VRGQHH8SE3CK5WYYTM', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-9', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'scalar::feature_name=complexity_of_intents|value=simple', 'scalar::feature_name=open_endedness|value=no', 'scalar::feature_name=safety_concern|value=safe', 'closed_set::feature_name=subject_of_expertise|constraints=Sociology', 'open_set::feature_name=type_of_in_context_material|check_for_existence=1'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J60JQJ136YV082P79QJW', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01J1QR3TJX5T9WRPYSNQ9EJ49V', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='jupiter-cs-aus-164.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J5VRGQHH8SE3CK5WYYTM', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='46.5', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J5X3ZKWDVMS5NCRGX7K2', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J5X3ZKWDVMS5NCRGX7K2'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01J1QR3TJX5T9WRPYSNQ9EJ49V', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=46.5, memory=None, gpus=('GPU-0210a94c-5c9e-db64-f99b-75396dd2fcc9', 'GPU-05acbb4f-0bb3-5a37-ac17-a3cd5a37bdb9')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J5X3ZKWDVMS5NCRGX7K2'), preemptible=True)))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job(id='01J6T8J4JDYQJ3REARYYVYBW8S', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 21, 2, 21, 312990, tzinfo=TzInfo(UTC)), exited=None, failed=None, finalized=None, canceled=None, canceled_for=None, canceled_code=None, idle_since=None, ready=datetime.datetime(2024, 9, 2, 21, 2, 16, 760085, tzinfo=TzInfo(UTC)), exit_code=None, message=None), name='get-features-datamodel-0', cluster=None, execution=JobExecution(task='01J6T8J4DH0WZF4SN48XQWM6EM', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-0', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'bertscore_length::min_val=0.33|max_val=0.67', 'cosine_sim::min_val=0.67|max_val=1.0', 'entity_sim::min_val=0.0|max_val=0.33', 'rouge::min_val=0.0|max_val=0.33', 'token_len_diff::min_val=0.67|max_val=1.0'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J4JDYQJ3REARYYVYBW8S', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01GTJAB9KQBFKSWTKVYPTAW97Z', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-50.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J4DH0WZF4SN48XQWM6EM', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='31', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J4EX7WJP3W3EB36ADDXR', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J4EX7WJP3W3EB36ADDXR'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01GTJAB9KQBFKSWTKVYPTAW97Z', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=31.0, memory=None, gpus=('GPU-0b766d18-9021-0813-f0e6-079c3ca46da7', 'GPU-59671ece-e605-9320-2825-4921e70b835e')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J4EX7WJP3W3EB36ADDXR'), preemptible=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.jobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experiment(id='01J6T8J4DC8PDTE5AT7NCJE8X6', name=None, full_name=None, description='Get features using datamodel approach', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, workspace_ref=WorkspaceRef(id='01HPMTGH3Z5P5AF1NVJ2W7B6KR', name='ljm-oe-adapt', full_name='ai2/ljm-oe-adapt'), jobs=(Job(id='01J6T8J4JDYQJ3REARYYVYBW8S', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 21, 2, 21, 312990, tzinfo=TzInfo(UTC)), exited=None, failed=None, finalized=None, canceled=None, canceled_for=None, canceled_code=None, idle_since=None, ready=datetime.datetime(2024, 9, 2, 21, 2, 16, 760085, tzinfo=TzInfo(UTC)), exit_code=None, message=None), name='get-features-datamodel-0', cluster=None, execution=JobExecution(task='01J6T8J4DH0WZF4SN48XQWM6EM', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-0', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'bertscore_length::min_val=0.33|max_val=0.67', 'cosine_sim::min_val=0.67|max_val=1.0', 'entity_sim::min_val=0.0|max_val=0.33', 'rouge::min_val=0.0|max_val=0.33', 'token_len_diff::min_val=0.67|max_val=1.0'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J4JDYQJ3REARYYVYBW8S', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01GTJAB9KQBFKSWTKVYPTAW97Z', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-50.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J4DH0WZF4SN48XQWM6EM', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='31', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J4EX7WJP3W3EB36ADDXR', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J4EX7WJP3W3EB36ADDXR'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01GTJAB9KQBFKSWTKVYPTAW97Z', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=31.0, memory=None, gpus=('GPU-0b766d18-9021-0813-f0e6-079c3ca46da7', 'GPU-59671ece-e605-9320-2825-4921e70b835e')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J4EX7WJP3W3EB36ADDXR'), preemptible=True), Job(id='01J6T8J4QE1X9R6AWW4NXTBXQQ', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 21, 2, 21, 311585, tzinfo=TzInfo(UTC)), exited=None, failed=None, finalized=None, canceled=None, canceled_for=None, canceled_code=None, idle_since=None, ready=datetime.datetime(2024, 9, 2, 21, 2, 16, 759997, tzinfo=TzInfo(UTC)), exit_code=None, message=None), name='get-features-datamodel-1', cluster=None, execution=JobExecution(task='01J6T8J4JKNRV85MJWJ0YFGR3V', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-1', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'bertscore_length::min_val=0.33|max_val=0.67', 'cosine_sim::min_val=0.67|max_val=1.0', 'entity_sim::min_val=0.0|max_val=0.33', 'rouge::min_val=0.0|max_val=0.33', 'token_len_diff::min_val=0.67|max_val=1.0'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J4QE1X9R6AWW4NXTBXQQ', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01GTJAB9KQBFKSWTKVYPTAW97Z', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-50.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J4JKNRV85MJWJ0YFGR3V', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='31', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J4KYW8XPB95NNQJ1EGHE', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J4KYW8XPB95NNQJ1EGHE'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01GTJAB9KQBFKSWTKVYPTAW97Z', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=31.0, memory=None, gpus=('GPU-f17000b0-6b5a-5954-1cd8-14aec898cb09', 'GPU-86b88a9c-569e-36d8-4784-bff425248ae1')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J4KYW8XPB95NNQJ1EGHE'), preemptible=True), Job(id='01J6T8J4WAHKY9N3PXT6EBSQS0', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 45, 888643, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 21, 7, 50, 10227, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 21, 8, 0, 673274, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 21, 7, 49, 942219, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 45, 146555, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-2', cluster=None, execution=JobExecution(task='01J6T8J4QN0ECMN97KM99KAF4Z', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-2', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'bertscore_length::min_val=0.33|max_val=0.67', 'cosine_sim::min_val=0.67|max_val=1.0', 'entity_sim::min_val=0.0|max_val=0.33', 'token_len_diff::min_val=0.67|max_val=1.0'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J4WAHKY9N3PXT6EBSQS0', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01J1QQSRH28MAMC5HKW4W87W1M', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='jupiter-cs-aus-219.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J4QN0ECMN97KM99KAF4Z', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='46.5', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J4RZN16TTPCFT1RXJZYW', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J4RZN16TTPCFT1RXJZYW'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01J1QQSRH28MAMC5HKW4W87W1M', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=46.5, memory=None, gpus=('GPU-6b0d84b9-d255-572f-c67a-09603f286127', 'GPU-d863315a-ed74-044c-1387-322ff0c09b5f')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J4RZN16TTPCFT1RXJZYW'), preemptible=True), Job(id='01J6T8J51CR3H4VJSZ0YTV827D', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 45, 428571, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 21, 7, 46, 895027, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 21, 7, 58, 475740, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 21, 7, 46, 741499, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 44, 643580, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-3', cluster=None, execution=JobExecution(task='01J6T8J4WHKVT8DZ2W5XAKQX9Z', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-3', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'bertscore_length::min_val=0.33|max_val=0.67', 'cosine_sim::min_val=0.67|max_val=1.0', 'entity_sim::min_val=0.0|max_val=0.33', 'scalar::feature_name=open_endedness|value=high', 'prompt_len::min_val=0.67|max_val=1.0'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J51CR3H4VJSZ0YTV827D', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01J1QQSRH28MAMC5HKW4W87W1M', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='jupiter-cs-aus-219.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J4WHKVT8DZ2W5XAKQX9Z', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='46.5', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J4XVTZFXYV6F0NBPJ4TY', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J4XVTZFXYV6F0NBPJ4TY'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01J1QQSRH28MAMC5HKW4W87W1M', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=46.5, memory=None, gpus=('GPU-19ccfe32-1d10-e652-d8a2-fc456ed9f853', 'GPU-884ba3d1-46f6-0b84-d39d-03dc96606a8b')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J4XVTZFXYV6F0NBPJ4TY'), preemptible=True), Job(id='01J6T8J56B52X1FWGP5RNQKJAT', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 45, 982994, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 21, 10, 39, 737623, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 21, 10, 42, 908728, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 21, 10, 39, 706947, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 44, 864911, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-4', cluster=None, execution=JobExecution(task='01J6T8J51K6EFBH0V86HCK62V6', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-4', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'bertscore_length::min_val=0.33|max_val=0.67', 'cosine_sim::min_val=0.67|max_val=1.0', 'entity_sim::min_val=0.0|max_val=0.33', 'prompt_len::min_val=0.67|max_val=1.0'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J56B52X1FWGP5RNQKJAT', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01GQHF8W7VTWHJCBRMK6CPMQPD', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-51.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J51K6EFBH0V86HCK62V6', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='23.25', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J52YHMS1WGVHFMKFBZ4Q', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J52YHMS1WGVHFMKFBZ4Q'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01GQHF8W7VTWHJCBRMK6CPMQPD', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=23.25, memory=None, gpus=('GPU-5c0a5e30-6d5c-516d-bf70-0aa12ef5f45b', 'GPU-62a22913-899f-d6c7-fa85-4f209d03fb2b')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J52YHMS1WGVHFMKFBZ4Q'), preemptible=True), Job(id='01J6T8J5BT7GPDVNMAG7MD8CN9', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 45, 565806, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 21, 9, 59, 281976, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 21, 10, 1, 931308, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 21, 9, 59, 249384, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 44, 524769, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-5', cluster=None, execution=JobExecution(task='01J6T8J56JNJ8J5RRM87Z029ER', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-5', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'bertscore_length::min_val=0.33|max_val=0.67', 'cosine_sim::min_val=0.67|max_val=1.0', 'entity_sim::min_val=0.0|max_val=0.33'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J5BT7GPDVNMAG7MD8CN9', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01GQHF8W7VTWHJCBRMK6CPMQPD', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-51.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J56JNJ8J5RRM87Z029ER', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='23.25', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J58A76W82WKMCBK8Y7BG', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J58A76W82WKMCBK8Y7BG'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01GQHF8W7VTWHJCBRMK6CPMQPD', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=23.25, memory=None, gpus=('GPU-b7acce8a-0aeb-48f1-49e7-36adeb4e0186', 'GPU-fc3efdee-1954-6d5f-79b0-0a60d48c3379')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J58A76W82WKMCBK8Y7BG'), preemptible=True), Job(id='01J6T8J5GPEAEWTEZ3FRVSDET2', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 43, 21794, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 21, 0, 20, 302117, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 21, 0, 23, 145600, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 21, 0, 20, 271581, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 41, 867351, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-6', cluster=None, execution=JobExecution(task='01J6T8J5C0CFA12F3ER6QRBPQ2', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-6', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'scalar::feature_name=complexity_of_intents|value=simple', 'scalar::feature_name=open_endedness|value=no', 'scalar::feature_name=safety_concern|value=safe', 'token_len_diff::min_val=0.67|max_val=1.0', 'open_set::feature_name=type_of_in_context_material|check_for_existence=1'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J5GPEAEWTEZ3FRVSDET2', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01HAAXJVZK8PKWEPZZE7JT1QKW', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-68.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J5C0CFA12F3ER6QRBPQ2', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='31', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J5DB8E2WM85CM43T6NS4', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J5DB8E2WM85CM43T6NS4'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01HAAXJVZK8PKWEPZZE7JT1QKW', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=31.0, memory=None, gpus=('GPU-05c4700c-b41c-a424-e4db-f75646533ce2', 'GPU-0b642c3c-0d0b-e891-953d-a8402e4a6a3b')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J5DB8E2WM85CM43T6NS4'), preemptible=True), Job(id='01J6T8J5P9RRSF6HNXCSZ6M5M7', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 42, 860262, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 20, 59, 51, 98874, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 20, 59, 51, 586852, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 20, 59, 51, 71016, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 41, 570045, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-7', cluster=None, execution=JobExecution(task='01J6T8J5GWHPQ1HCT3B6CVPZ88', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-7', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'scalar::feature_name=complexity_of_intents|value=simple', 'scalar::feature_name=safety_concern|value=safe'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J5P9RRSF6HNXCSZ6M5M7', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01HAAXJVZK8PKWEPZZE7JT1QKW', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-68.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J5GWHPQ1HCT3B6CVPZ88', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='31', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J5JDE51K6WKGEF5A9KNK', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J5JDE51K6WKGEF5A9KNK'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01HAAXJVZK8PKWEPZZE7JT1QKW', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=31.0, memory=None, gpus=('GPU-0fc76d68-bea2-abb1-66be-8d86c0c63e78', 'GPU-50bbab5a-c8dc-6d23-1d4d-f44506094e31')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J5JDE51K6WKGEF5A9KNK'), preemptible=True), Job(id='01J6T8J5VJSNJ0GDYT7D4M67RF', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 43, 596458, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 20, 59, 52, 107020, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 20, 59, 52, 598888, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 20, 59, 52, 78899, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 42, 380621, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-8', cluster=None, execution=JobExecution(task='01J6T8J5PHY6ZF899Q1ME47N8N', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-8', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'scalar::feature_name=complexity_of_intents|value=simple', 'scalar::feature_name=safety_concern|value=safe', 'closed_set::feature_name=subject_of_expertise|constraints=Literature', 'open_set::feature_name=type_of_in_context_material|check_for_existence=1'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J5VJSNJ0GDYT7D4M67RF', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01HAAXJVZK8PKWEPZZE7JT1QKW', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='allennlp-cirrascale-68.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J5PHY6ZF899Q1ME47N8N', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='31', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J5R11SM2F2S7DPBSB3RN', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J5R11SM2F2S7DPBSB3RN'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01HAAXJVZK8PKWEPZZE7JT1QKW', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=31.0, memory=None, gpus=('GPU-d46323ef-46b4-12ca-0e6d-80606993c3ee', 'GPU-2a71f6b8-760f-2ffd-597e-18dc03093426')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J5R11SM2F2S7DPBSB3RN'), preemptible=True), Job(id='01J6T8J60JQJ136YV082P79QJW', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 42, 801772, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 20, 59, 48, 997820, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 20, 59, 49, 679428, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 20, 59, 48, 913565, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 42, 214032, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-9', cluster=None, execution=JobExecution(task='01J6T8J5VRGQHH8SE3CK5WYYTM', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-9', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'scalar::feature_name=complexity_of_intents|value=simple', 'scalar::feature_name=open_endedness|value=no', 'scalar::feature_name=safety_concern|value=safe', 'closed_set::feature_name=subject_of_expertise|constraints=Sociology', 'open_set::feature_name=type_of_in_context_material|check_for_existence=1'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J60JQJ136YV082P79QJW', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01J1QR3TJX5T9WRPYSNQ9EJ49V', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='jupiter-cs-aus-164.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J5VRGQHH8SE3CK5WYYTM', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='46.5', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J5X3ZKWDVMS5NCRGX7K2', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J5X3ZKWDVMS5NCRGX7K2'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01J1QR3TJX5T9WRPYSNQ9EJ49V', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=46.5, memory=None, gpus=('GPU-0210a94c-5c9e-db64-f99b-75396dd2fcc9', 'GPU-05acbb4f-0bb3-5a37-ac17-a3cd5a37bdb9')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J5X3ZKWDVMS5NCRGX7K2'), preemptible=True)))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job(id='01J6T8J4WAHKY9N3PXT6EBSQS0', kind='execution', author=Account(id='01HEY8JWVQ71HNYVPN7CZWJ5C1', name='ljm', display_name='Lj Miranda', institution=None, pronouns='', email=None), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', status=JobStatus(created=datetime.datetime(2024, 9, 2, 20, 59, 27, 532028, tzinfo=TzInfo(UTC)), scheduled=datetime.datetime(2024, 9, 2, 20, 59, 39, 420983, tzinfo=TzInfo(UTC)), started=datetime.datetime(2024, 9, 2, 20, 59, 45, 888643, tzinfo=TzInfo(UTC)), exited=datetime.datetime(2024, 9, 2, 21, 7, 50, 10227, tzinfo=TzInfo(UTC)), failed=None, finalized=datetime.datetime(2024, 9, 2, 21, 8, 0, 673274, tzinfo=TzInfo(UTC)), canceled=None, canceled_for=None, canceled_code=None, idle_since=datetime.datetime(2024, 9, 2, 21, 7, 49, 942219, tzinfo=TzInfo(UTC)), ready=datetime.datetime(2024, 9, 2, 20, 59, 45, 146555, tzinfo=TzInfo(UTC)), exit_code=0, message=None), name='get-features-datamodel-2', cluster=None, execution=JobExecution(task='01J6T8J4QN0ECMN97KM99KAF4Z', experiment='01J6T8J4DC8PDTE5AT7NCJE8X6', spec=TaskSpec(image=ImageSource(beaker='01J6T7ZY6N0F8RKTW0FKVJ35CW', docker=None), result=ResultSpec(path='/output'), context=TaskContext(cluster=None, priority='normal', preemptible=True), constraints=Constraints(cluster=['ai2/allennlp-cirrascale', 'ai2/jupiter-cirrascale-2'], hostname=None), name='get-features-datamodel-2', command=['python', '-m', 'scripts.apply_data_model', 'single'], arguments=['--input_path', '/source/helpsteer2_human_vs_gpt4_weighted_for_llama.jsonl', '--output_dir', '/output/data/', '--num_instances', '7000', '--threshold', '1', '--keep_features_dir', '/output/features/', '--append_to_experiments_file', '/output/experiments.txt', '--features', 'bertscore_length::min_val=0.33|max_val=0.67', 'cosine_sim::min_val=0.67|max_val=1.0', 'entity_sim::min_val=0.0|max_val=0.33', 'token_len_diff::min_val=0.67|max_val=1.0'], env_vars=[EnvVar(name='OPENAI_API_KEY', value=None, secret='OPENAI_API_KEY'), EnvVar(name='TOKENIZERS_PARALLELISM', value='false', secret=None), EnvVar(name='BEAKER_JOB_ID', value='01J6T8J4WAHKY9N3PXT6EBSQS0', secret=None), EnvVar(name='BEAKER_JOB_KIND', value='batch', secret=None), EnvVar(name='BEAKER_WORKLOAD_ID', value='01J6T8J4DC8PDTE5AT7NCJE8X6', secret=None), EnvVar(name='BEAKER_NODE_ID', value='01J1QQSRH28MAMC5HKW4W87W1M', secret=None), EnvVar(name='BEAKER_NODE_HOSTNAME', value='jupiter-cs-aus-219.reviz.ai2.in', secret=None), EnvVar(name='BEAKER_TASK_ID', value='01J6T8J4QN0ECMN97KM99KAF4Z', secret=None), EnvVar(name='BEAKER_ASSIGNED_GPU_COUNT', value='2', secret=None), EnvVar(name='BEAKER_ASSIGNED_CPU_COUNT', value='46.5', secret=None), EnvVar(name='BEAKER_RESULT_DATASET_ID', value='01J6T8J4RZN16TTPCFT1RXJZYW', secret=None)], datasets=[DataMount(source=DataSource(beaker='01J6KBM2VCM9EQ7MER26VBXCCM', host_path=None, weka=None, result=None, secret=None), mount_path='/source', sub_path=None)], resources=TaskResources(cpu_count=None, gpu_count=2, memory=None, shared_memory=None), host_networking=False, replicas=None, leader_selection=False, propagate_failure=None, propagate_preemption=None, synchronized_start_timeout=None), result=ExecutionResult(beaker='01J6T8J4RZN16TTPCFT1RXJZYW'), workspace='01HPMTGH3Z5P5AF1NVJ2W7B6KR', replica_rank=None, replica_group_id=None), execution_results=None, node='01J1QQSRH28MAMC5HKW4W87W1M', node_has_gpus=True, requests=JobRequests(gpu_count=2, cpu_count=None, memory=None, shared_memory=None), limits=JobLimits(cpu_count=46.5, memory=None, gpus=('GPU-6b0d84b9-d255-572f-c67a-09603f286127', 'GPU-d863315a-ed74-044c-1387-322ff0c09b5f')), session=None, host_networking=False, port_mappings=None, result=ExecutionResult(beaker='01J6T8J4RZN16TTPCFT1RXJZYW'), preemptible=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72c294b3a884e5f942661e23ba58209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileExistsError",
     "evalue": "experiments.txt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbeaker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeaker\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Work/human-pref-datamodel/venv/lib/python3.11/site-packages/beaker/services/dataset.py:280\u001b[0m, in \u001b[0;36mDatasetClient.fetch\u001b[0;34m(self, dataset, target, prefix, force, max_workers, quiet, validate_checksum, chunk_size)\u001b[0m\n\u001b[1;32m    278\u001b[0m target_path \u001b[38;5;241m=\u001b[39m target \u001b[38;5;241m/\u001b[39m Path(file_info\u001b[38;5;241m.\u001b[39mpath)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force \u001b[38;5;129;01mand\u001b[39;00m target_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m(file_info\u001b[38;5;241m.\u001b[39mpath)\n\u001b[1;32m    281\u001b[0m future \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_file,\n\u001b[1;32m    283\u001b[0m     dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    289\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size,\n\u001b[1;32m    290\u001b[0m )\n\u001b[1;32m    291\u001b[0m download_futures\u001b[38;5;241m.\u001b[39mappend(future)\n",
      "\u001b[0;31mFileExistsError\u001b[0m: experiments.txt"
     ]
    }
   ],
   "source": [
    "beaker.dataset.fetch(jobs[0].execution.result.beaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
