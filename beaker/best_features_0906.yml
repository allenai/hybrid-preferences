version: v2
budget: ai2/oe-adapt
description: "Get features using datamodel approach"
tasks:
  # Multipref
  - name: get-features-datamodel-multipref-lgbm
    image:
      beaker: ljm/human-datamodel
    command: ["python", "-m", "scripts.apply_data_model", "single"]
    arguments:
      - --input_path
      - /source/multipref_human_vs_gpt4_overall.jsonl
      - --output_dir
      - /output/data/
      - --num_instances
      - 7000
      - --threshold
      - 1
      - --keep_features_dir
      - /output/features/
      - --append_to_experiments_file
      - /output/experiments.txt
      - --min_num_swaps
      - 10
      - --features
      - scalar::feature_name=complexity_of_intents|value=simple
      - scalar::feature_name=safety_concern|value=safe
      - scalar::feature_name=open_endedness|value=no
      - token_len_diff::min_val=0.33|max_val=0.67
      - open_set::feature_name=type_of_in_context_material|check_for_existence=1
    datasets:
      - mountPath: /source/
        source:
          beaker: 01J6WJTFY5YRXJYPJQ8BE6GT7J
    result:
      path: /output
    resources:
      gpuCount: 1
    context:
      priority: normal
      preemptible: true
    constraints:
      cluster:
        - ai2/allennlp-cirrascale
        - ai2/jupiter-cirrascale-2
    envVars:
      - name: OPENAI_API_KEY
        secret: OPENAI_API_KEY
      - name: TOKENIZERS_PARALLELISM
        value: "false"
  - name: get-features-datamodel-multipref-linear
    image:
      beaker: ljm/human-datamodel
    command: ["python", "-m", "scripts.apply_data_model", "single"]
    arguments:
      - --input_path
      - /source/multipref_human_vs_gpt4_overall.jsonl
      - --output_dir
      - /output/data/
      - --num_instances
      - 7000
      - --threshold
      - 1
      - --keep_features_dir
      - /output/features/
      - --append_to_experiments_file
      - /output/experiments.txt
      - --min_num_swaps
      - 10
      - --features
      - bertscore::min_val=0.67|max_val=1.0
      - scalar::feature_name=complexity_of_intents|value=simple
      - scalar::feature_name=safety_concern|value=moderate
    datasets:
      - mountPath: /source/
        source:
          beaker: 01J6WJTFY5YRXJYPJQ8BE6GT7J
    result:
      path: /output
    resources:
      gpuCount: 1
    context:
      priority: normal
      preemptible: true
    constraints:
      cluster:
        - ai2/allennlp-cirrascale
        - ai2/jupiter-cirrascale-2
    envVars:
      - name: OPENAI_API_KEY
        secret: OPENAI_API_KEY
      - name: TOKENIZERS_PARALLELISM
        value: "false"
  # Alpacafarm
  - name: get-features-datamodel-alpacafarm-lgbm
    image:
      beaker: ljm/human-datamodel
    command: ["python", "-m", "scripts.apply_data_model", "single"]
    arguments:
      - --input_path
      - /source/alpacafarm_human_vs_gpt4_alpacaeval.jsonl
      - --output_dir
      - /output/data/
      - --num_instances
      - 7000
      - --threshold
      - 1
      - --keep_features_dir
      - /output/features/
      - --append_to_experiments_file
      - /output/experiments.txt
      - --min_num_swaps
      - 10
      - --features
      - scalar::feature_name=complexity_of_intents|value=simple
      - scalar::feature_name=safety_concern|value=safe
      - scalar::feature_name=open_endedness|value=no
      - token_len_diff::min_val=0.33|max_val=0.67
      - open_set::feature_name=type_of_in_context_material|check_for_existence=1
    datasets:
      - mountPath: /source/
        source:
          beaker: 01J71RZNDFQ1M50V3BYRXXZCBF
    result:
      path: /output
    resources:
      gpuCount: 1
    context:
      priority: normal
      preemptible: true
    constraints:
      cluster:
        - ai2/allennlp-cirrascale
        - ai2/jupiter-cirrascale-2
    envVars:
      - name: OPENAI_API_KEY
        secret: OPENAI_API_KEY
      - name: TOKENIZERS_PARALLELISM
        value: "false"
  - name: get-features-datamodel-alpacafarm-linear
    image:
      beaker: ljm/human-datamodel
    command: ["python", "-m", "scripts.apply_data_model", "single"]
    arguments:
      - --input_path
      - /source/alpacafarm_human_vs_gpt4_alpacaeval.jsonl
      - --output_dir
      - /output/data/
      - --num_instances
      - 7000
      - --threshold
      - 1
      - --keep_features_dir
      - /output/features/
      - --append_to_experiments_file
      - /output/experiments.txt
      - --min_num_swaps
      - 10
      - --features
      - bertscore::min_val=0.67|max_val=1.0
      - scalar::feature_name=complexity_of_intents|value=simple
      - scalar::feature_name=safety_concern|value=moderate
    datasets:
      - mountPath: /source/
        source:
          beaker: 01J71RZNDFQ1M50V3BYRXXZCBF
    result:
      path: /output
    resources:
      gpuCount: 1
    context:
      priority: normal
      preemptible: true
    constraints:
      cluster:
        - ai2/allennlp-cirrascale
        - ai2/jupiter-cirrascale-2
    envVars:
      - name: OPENAI_API_KEY
        secret: OPENAI_API_KEY
      - name: TOKENIZERS_PARALLELISM
        value: "false"
  # ChatArena
  - name: get-features-datamodel-chatarena-lgbm
    image:
      beaker: ljm/human-datamodel
    command: ["python", "-m", "scripts.apply_data_model", "single"]
    arguments:
      - --input_path
      - /source/chatarena_human_vs_gpt4_alpacaeval.jsonl
      - --output_dir
      - /output/data/
      - --num_instances
      - 7000
      - --threshold
      - 1
      - --keep_features_dir
      - /output/features/
      - --append_to_experiments_file
      - /output/experiments.txt
      - --min_num_swaps
      - 10
      - --features
      - scalar::feature_name=complexity_of_intents|value=simple
      - scalar::feature_name=safety_concern|value=safe
      - scalar::feature_name=open_endedness|value=no
      - token_len_diff::min_val=0.33|max_val=0.67
      - open_set::feature_name=type_of_in_context_material|check_for_existence=1
    datasets:
      - mountPath: /source/
        source:
          beaker: 01J71REDEZ701ZHY7EAANHD5ZF
    result:
      path: /output
    resources:
      gpuCount: 1
    context:
      priority: normal
      preemptible: true
    constraints:
      cluster:
        - ai2/allennlp-cirrascale
        - ai2/jupiter-cirrascale-2
    envVars:
      - name: OPENAI_API_KEY
        secret: OPENAI_API_KEY
      - name: TOKENIZERS_PARALLELISM
        value: "false"
  - name: get-features-datamodel-chatarena-linear
    image:
      beaker: ljm/human-datamodel
    command: ["python", "-m", "scripts.apply_data_model", "single"]
    arguments:
      - --input_path
      - /source/chatarena_human_vs_gpt4_alpacaeval.jsonl
      - --output_dir
      - /output/data/
      - --num_instances
      - 7000
      - --threshold
      - 1
      - --keep_features_dir
      - /output/features/
      - --append_to_experiments_file
      - /output/experiments.txt
      - --min_num_swaps
      - 10
      - --features
      - bertscore::min_val=0.67|max_val=1.0
      - scalar::feature_name=complexity_of_intents|value=simple
      - scalar::feature_name=safety_concern|value=moderate
    datasets:
      - mountPath: /source/
        source:
          beaker: 01J71REDEZ701ZHY7EAANHD5ZF
    result:
      path: /output
    resources:
      gpuCount: 1
    context:
      priority: normal
      preemptible: true
    constraints:
      cluster:
        - ai2/allennlp-cirrascale
        - ai2/jupiter-cirrascale-2
    envVars:
      - name: OPENAI_API_KEY
        secret: OPENAI_API_KEY
      - name: TOKENIZERS_PARALLELISM
        value: "false"
